{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed(42)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(train_data, test_data):\n",
    "    # Drop the specified columns\n",
    "    columns_to_drop = ['Alley', 'PoolQC', 'MiscFeature', 'Fence']\n",
    "    train_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "    test_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "    # Select relevant features\n",
    "    features = ['LotFrontage', 'LotArea', 'Neighborhood']\n",
    "    data_train = train_data[features]\n",
    "    data_train = pd.get_dummies(data_train)\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled_train = scaler.fit_transform(data_train)\n",
    "\n",
    "    # KNN Imputer for train data\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    data_imputed_train = imputer.fit_transform(data_scaled_train)\n",
    "\n",
    "    # Convert the scaled data back to the original scale for train data\n",
    "    data_imputed_original_scale_train = scaler.inverse_transform(data_imputed_train)\n",
    "\n",
    "    # Update LotFrontage in train_data\n",
    "    train_data['LotFrontage'] = data_imputed_original_scale_train[:, data_train.columns.get_loc('LotFrontage')]\n",
    "\n",
    "    # Process test data \n",
    "    data_test = test_data[features]\n",
    "    data_test = pd.get_dummies(data_test, columns=['Neighborhood'])\n",
    "\n",
    "    # Align columns of test data with train data\n",
    "    data_test = data_test.reindex(columns = data_train.columns, fill_value=0)\n",
    "\n",
    "    # Standardize test data\n",
    "    data_scaled_test = scaler.transform(data_test)\n",
    "\n",
    "    # KNN Imputer for test data\n",
    "    imputer_test = KNNImputer(n_neighbors=5)\n",
    "    data_imputed_test = imputer_test.fit_transform(data_scaled_test)\n",
    "\n",
    "    # Convert the scaled data back to the original scale for test data\n",
    "    data_imputed_test_scale = scaler.inverse_transform(data_imputed_test)\n",
    "\n",
    "    # Update LotFrontage in test_data\n",
    "    test_data['LotFrontage'] = data_imputed_test_scale[:, data_test.columns.get_loc('LotFrontage')]\n",
    "\n",
    "    # Fill missing values for 'GarageYrBlt' and 'MasVnrArea' with zeros\n",
    "    train_data['GarageYrBlt'].fillna(0, inplace=True)\n",
    "    test_data['GarageYrBlt'].fillna(0, inplace=True)\n",
    "    train_data['MasVnrArea'].fillna(0, inplace=True)\n",
    "    test_data['MasVnrArea'].fillna(0, inplace=True)\n",
    "\n",
    "    # Identify numerical features and fill missing values with their median\n",
    "    numerical_features = train_data.select_dtypes(include=[np.number])\n",
    "    numerical_features.fillna(numerical_features.median(), inplace=True)\n",
    "    numerical_features_test = test_data.select_dtypes(include=[np.number])\n",
    "    numerical_features_test.fillna(numerical_features_test.median(), inplace=True)\n",
    "    \n",
    "    # Dropping features with low or negative correlations\n",
    "    features_to_drop = [\n",
    "        'KitchenAbvGr', 'EnclosedPorch', \n",
    "        'OverallCond', 'LowQualFinSF', \n",
    "        'MSSubClass', 'Unnamed: 0', \n",
    "        'Id', 'MiscVal',\n",
    "        'YrSold','LotFrontage',\n",
    "        'BsmtHalfBath', 'BsmtFinSF2'\n",
    "    ]\n",
    "    # Dropping the features from the DataFrame\n",
    "    test_data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    train_data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    features_to_drop = [\n",
    "         'GarageArea' ,'TotalBsmtSF','TotRmsAbvGrd'\n",
    "    ]\n",
    "    train_data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    test_data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    categorical_cols_with_missing = ['MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']\n",
    "    # Fill missing values with the most common value in each categorical column\n",
    "    for col in categorical_cols_with_missing:\n",
    "        mode_value = train_data[col].mode()[0]  # Get the mode value for the column\n",
    "        train_data[col].fillna(mode_value, inplace=True)\n",
    "    categorical_cols_with_missing_test = ['MasVnrType', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'FireplaceQu', 'GarageType', 'GarageQual']\n",
    "    for col in categorical_cols_with_missing_test:\n",
    "        mode_value = test_data[col].mode()[0]\n",
    "        test_data[col].fillna(mode_value, inplace=True)\n",
    "        \n",
    "    features_to_drop = [\n",
    "         'Street' ,'Utilities','LotConfig','Condition2','BldgType','HouseStyle','RoofMatl',\n",
    "        'Exterior1st','Exterior2nd','ExterCond','BsmtCond','Heating','HeatingQC','CentralAir',\n",
    "        'Electrical','Functional','GarageCond','GarageFinish','PavedDrive','BsmtFinType2'\n",
    "    ]\n",
    "    train_data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    test_data.drop(features_to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    lot_shape_mapping = {\n",
    "        'Reg': 1,\n",
    "        'IR1': 2,\n",
    "        'IR2': 3,\n",
    "        'IR3': 4\n",
    "    }\n",
    "\n",
    "    # Apply the mapping to your DataFrame\n",
    "    train_data['LotShape_Ordinal'] = train_data['LotShape'].map(lot_shape_mapping)\n",
    "    # Create the interaction term\n",
    "    train_data['LotArea_Shape_Interaction'] = train_data['LotArea'] * train_data['LotShape_Ordinal']\n",
    "    # Drop the original 'LotArea' and 'LotShape' columns\n",
    "    train_data.drop(['LotArea', 'LotShape'], axis=1, inplace=True)\n",
    "    test_data['LotShape_Ordinal'] = test_data['LotShape'].map(lot_shape_mapping)\n",
    "    test_data['LotArea_Shape_Interaction'] = test_data['LotArea'] * test_data['LotShape_Ordinal']\n",
    "    test_data.drop(['LotArea', 'LotShape'], axis=1, inplace=True)\n",
    "    \n",
    "    #Drop '1stFlrSF ’，‘2ndFlrSF’\n",
    "    train_data.drop(['1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)\n",
    "    test_data.drop(['1stFlrSF', '2ndFlrSF'], axis=1, inplace=True)\n",
    "    \n",
    "    train_data['TotalBsmtSF'] = train_data['BsmtFinSF1'] + train_data['BsmtUnfSF']\n",
    "    train_data.drop(['BsmtFinSF1', 'BsmtUnfSF'], axis=1, inplace=True)\n",
    "    test_data['TotalBsmtSF'] = test_data['BsmtFinSF1'] + test_data['BsmtUnfSF']\n",
    "    test_data.drop(['BsmtFinSF1', 'BsmtUnfSF'], axis=1, inplace=True)\n",
    "    \n",
    "    # Calculate the total number of bathrooms\n",
    "    test_data['TotalBaths'] = test_data['BsmtFullBath'] + test_data['FullBath'] + (test_data['HalfBath'] * 0.5)\n",
    "    test_data.drop(['BsmtFullBath', 'FullBath', 'HalfBath'], axis=1, inplace=True)\n",
    "    train_data['TotalBaths'] = train_data['BsmtFullBath'] + train_data['FullBath'] + (train_data['HalfBath'] * 0.5)\n",
    "    train_data.drop(['BsmtFullBath', 'FullBath', 'HalfBath'], axis=1, inplace=True)\n",
    "    \n",
    "    train_data.drop(['3SsnPorch', 'MoSold', 'ScreenPorch'], axis=1, inplace=True)\n",
    "    test_data.drop(['3SsnPorch', 'MoSold', 'ScreenPorch'], axis=1, inplace=True)\n",
    "    \n",
    "    # Binary encode the 'RoofStyle' column where '1' represents 'Gable' or 'Hip' roofs and '0' all others\n",
    "    train_data['RoofStyle_Binary'] = train_data['RoofStyle'].apply(lambda x: 1 if x in ['Gable', 'Hip'] else 0)\n",
    "    # Optionally, drop the original 'RoofStyle' column if you no longer need it\n",
    "    train_data.drop('RoofStyle', axis=1, inplace=True)\n",
    "    \n",
    "    test_data['RoofStyle_Binary'] = test_data['RoofStyle'].apply(lambda x: 1 if x in ['Gable', 'Hip'] else 0)\n",
    "    test_data.drop('RoofStyle', axis=1, inplace=True)\n",
    "    \n",
    "    train_data['MasVnrType_BrkFace'] = train_data['MasVnrType'].apply(lambda x: 1 if x == 'BrkFace' else 0)\n",
    "    train_data.drop('MasVnrType', axis=1, inplace=True)\n",
    "    \n",
    "    test_data['MasVnrType_BrkFace'] = test_data['MasVnrType'].apply(lambda x: 1 if x == 'BrkFace' else 0)\n",
    "    test_data.drop('MasVnrType', axis=1, inplace=True)\n",
    "    \n",
    "    # Define a mapping from quality ratings to numbers\n",
    "    quality_mapping = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "\n",
    "    # Apply ordinal encoding\n",
    "    for feature in ['ExterQual', 'BsmtQual', 'FireplaceQu', 'GarageQual','KitchenQual']:\n",
    "        train_data[feature] = train_data[feature].map(quality_mapping)\n",
    "    for feature in ['ExterQual', 'BsmtQual', 'FireplaceQu', 'GarageQual','KitchenQual']:\n",
    "        test_data[feature] = test_data[feature].map(quality_mapping)\n",
    "        \n",
    "    land_contour_mapping = {'Lvl': 4, 'Bnk': 3, 'HLS': 2, 'Low': 1}\n",
    "    train_data['LandContour'] = train_data['LandContour'].map(land_contour_mapping)\n",
    "    test_data['LandContour'] = test_data['LandContour'].map(land_contour_mapping)\n",
    "    \n",
    "    land_slope_mapping = {'Gtl': 3, 'Mod': 2, 'Sev': 1}\n",
    "    train_data['LandSlope'] = train_data['LandSlope'].map(land_slope_mapping)\n",
    "    test_data['LandSlope'] = test_data['LandSlope'].map(land_slope_mapping)\n",
    "    \n",
    "    ordinal_mapping = {\n",
    "        'No': 0,   # No Basement\n",
    "        'Unf': 1,  # Unfinished\n",
    "        'LwQ': 2,  # Low Quality\n",
    "        'Rec': 3,  # Average Quality\n",
    "        'BLQ': 4,  # Below Average Quality\n",
    "        'ALQ': 5,  # Average Living Quarters\n",
    "        'GLQ': 6   # Good Living Quarters\n",
    "    }\n",
    "\n",
    "    # Apply the mapping to the 'BsmtFinType1' column\n",
    "    train_data['BsmtFinType1'] = train_data['BsmtFinType1'].map(ordinal_mapping)\n",
    "    test_data['BsmtFinType1'] = test_data['BsmtFinType1'].map(ordinal_mapping)\n",
    "    \n",
    "    neighborhood_mapping = {\n",
    "        'CollgCr':1, 'Edwards':2, 'NAmes':3, 'Somerst':4, 'Timber':5, 'Veenker':6,\n",
    "           'OldTown':7, 'BrkSide':8, 'ClearCr':9, 'MeadowV':10, 'Mitchel':11, 'SawyerW':12,\n",
    "           'StoneBr':13, 'NoRidge':14, 'SWISU':15, 'Sawyer':16, 'Gilbert':17, 'IDOTRR':18,\n",
    "           'NridgHt':19, 'Blmngtn':20, 'NWAmes':21, 'Crawfor':22, 'BrDale':23, 'NPkVill':24\n",
    "    }\n",
    "    train_data['Neighborhood'] = train_data['Neighborhood'].map(neighborhood_mapping)\n",
    "    neighborhood_mapping_test = {\n",
    "        'NAmes':3, 'Somerst':4, 'Edwards':2, 'CollgCr':1, 'OldTown':7, 'StoneBr':13,\n",
    "           'IDOTRR':18, 'Crawfor':22, 'Gilbert':17, 'NridgHt':19, 'BrkSide':8, 'Sawyer':16,\n",
    "           'SWISU':15, 'NWAmes':21, 'NoRidge':14, 'Blmngtn':20, 'Mitchel':11, 'Blueste':25,\n",
    "           'SawyerW':12, 'Timber':5, 'NPkVill':24, 'MeadowV':10, 'ClearCr':9, 'BrDale':23,\n",
    "           'Veenker':6\n",
    "    }\n",
    "    test_data['Neighborhood'] = test_data['Neighborhood'].map(neighborhood_mapping_test)\n",
    "    \n",
    "    Condition1_mapping = {\n",
    "        'Norm':1, 'Feedr':2, 'RRAn':3, 'Artery':4, 'RRAe':5, 'RRNn':6, 'PosN':7, 'RRNe':8,\n",
    "           'PosA':9\n",
    "    }\n",
    "    test_data['Condition1'] = test_data['Condition1'].map(Condition1_mapping)\n",
    "    train_data['Condition1'] = train_data['Condition1'].map(Condition1_mapping)\n",
    "    \n",
    "    Foundation_mapping = {\n",
    "        'PConc':1, 'CBlock':2, 'BrkTil':3, 'Slab':4, 'Stone':5, 'Wood':6\n",
    "    }\n",
    "    test_data['Foundation'] = test_data['Foundation'].map(Foundation_mapping)\n",
    "    train_data['Foundation'] = train_data['Foundation'].map(Foundation_mapping)\n",
    "    \n",
    "    BsmtExposure_mapping = {\n",
    "        'No':0, 'Mn':1, 'Gd':2, 'Av':3\n",
    "    }\n",
    "    test_data['BsmtExposure'] = test_data['BsmtExposure'].map(BsmtExposure_mapping)\n",
    "    train_data['BsmtExposure'] = train_data['BsmtExposure'].map(BsmtExposure_mapping)\n",
    "    \n",
    "    GarageType_mapping = {\n",
    "        'Attchd':1, 'Detchd':2, 'BuiltIn':3, 'Basment':4, 'CarPort':5, '2Types':6\n",
    "    }\n",
    "    test_data['GarageType'] = test_data['GarageType'].map(GarageType_mapping)\n",
    "    train_data['GarageType'] = train_data['GarageType'].map(GarageType_mapping)\n",
    "    \n",
    "    SaleType_mapping_train = {\n",
    "        'WD':1, 'New':5, 'COD':3, 'CWD':8, 'ConLw':7, 'ConLD':2, 'ConLI':4, 'Oth':6, 'Con':9\n",
    "    }\n",
    "    train_data['SaleType'] = train_data['SaleType'].map(SaleType_mapping_train)\n",
    "    SaleType_mapping_test = {\n",
    "        'WD':1, 'ConLD':2, 'COD':3, 'ConLI':4, 'New':5, 'Oth':6, 'ConLw':7\n",
    "    }\n",
    "    test_data['SaleType'] = test_data['SaleType'].map(SaleType_mapping_test)\n",
    "    \n",
    "    SaleCondition_mapping = {\n",
    "        'Normal':1, 'Partial':2, 'Abnorml':3, 'Family':4, 'Alloca':5, 'AdjLand':6\n",
    "    }\n",
    "    test_data['SaleCondition'] = test_data['SaleCondition'].map(SaleCondition_mapping)\n",
    "    train_data['SaleCondition'] = train_data['SaleCondition'].map(SaleCondition_mapping)\n",
    "    \n",
    "    # Initialize the label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder_test = LabelEncoder()\n",
    "    # Fit and transform the 'MSZoning' feature\n",
    "    train_data['MSZoning'] = label_encoder.fit_transform(train_data['MSZoning'])\n",
    "    test_data['MSZoning'] = label_encoder_test.fit_transform(test_data['MSZoning'])\n",
    "    \n",
    "    # Identify the columns to exclude from standardization\n",
    "    cols_to_exclude = ['SalePrice']\n",
    "    # Select only the numeric features by excluding the specified columns\n",
    "    numeric_cols_test = test_data.select_dtypes(include=['number']).columns.tolist()\n",
    "    cols_to_standardize = [col for col in numeric_cols_test if col not in cols_to_exclude]\n",
    "    # Standardize the numeric columns that are not excluded\n",
    "    scaler_testdata = StandardScaler()\n",
    "    test_data[cols_to_standardize] = scaler.fit_transform(test_data[cols_to_standardize])\n",
    "\n",
    "    numeric_cols_train = train_data.select_dtypes(include=['number']).columns.tolist()\n",
    "    cols_to_standardize = [col for col in numeric_cols_test if col not in cols_to_exclude]\n",
    "    scaler_traindata = StandardScaler()\n",
    "    train_data[cols_to_standardize] = scaler.fit_transform(train_data[cols_to_standardize])\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b956ab7c35d4c1185c4ef6546198209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: MSE = 262980124.03118658\n",
      "Group 1: MSE = 7619871022.58241\n",
      "Group 2: MSE = 710767037.7397035\n",
      "Overall MSE for the test dataset: 979819208.3504664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      120500\n",
       "1      155000\n",
       "2      118000\n",
       "3      188000\n",
       "4      160000\n",
       "        ...  \n",
       "433    235000\n",
       "434    170000\n",
       "435    155000\n",
       "436    395192\n",
       "437    110500\n",
       "Name: SalePrice, Length: 438, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_data_prediction(train_data, test_data):\n",
    "    \n",
    "    train_data, test_data = data_processing(train_data, test_data)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "    train_clusters = kmeans.fit_predict(train_data)\n",
    "    train_data['Group'] = train_clusters\n",
    "\n",
    "    ##### Train classifier #####\n",
    "\n",
    "    X_train = train_data.drop('Group', axis=1)\n",
    "    y_train = train_data['Group']\n",
    "    clf = RandomForestClassifier(random_state=0)\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "    grid_search = GridSearchCV(clf, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    test_data['Group'] = grid_search.predict(test_data)\n",
    "    \n",
    "    ##### predict on test data #####\n",
    "    \n",
    "    group_models = {}\n",
    "    all_predictions = np.zeros(len(test_data))\n",
    "    for group in tqdm(test_data['Group'].unique()):\n",
    "        group_data_train = train_data[train_data['Group'] == group]\n",
    "        X_train_group = group_data_train.drop(['SalePrice', 'Group'], axis=1)\n",
    "        y_train_group = group_data_train['SalePrice']\n",
    "        group_data_test = test_data[test_data['Group'] == group]\n",
    "        X_test_group = group_data_test.drop(['SalePrice', 'Group'], axis=1)\n",
    "        y_test_group = group_data_test['SalePrice']\n",
    "        \n",
    "        estimators = [\n",
    "            ('lr', LinearRegression()),\n",
    "            ('dt', DecisionTreeRegressor(random_state=42)),\n",
    "            ('rf', RandomForestRegressor(random_state=42)),\n",
    "            ('svr', SVR())\n",
    "        ]\n",
    "        \n",
    "        stack_reg = StackingRegressor(estimators=estimators, final_estimator=RandomForestRegressor(random_state=42))\n",
    "        stack_reg.fit(X_train_group, y_train_group)\n",
    "        y_pred_group = stack_reg.predict(X_test_group)\n",
    "        all_predictions[group_data_test.index] = y_pred_group\n",
    "\n",
    "        # comparison_df = pd.DataFrame({\n",
    "        #     'Actual': y_test_group,\n",
    "        #     'Predicted': y_pred_group\n",
    "        # })\n",
    "        # comparison_df = comparison_df.reset_index(drop=True)\n",
    "        # print('For group', group)\n",
    "        # print(comparison_df)\n",
    "\n",
    "        mse = mean_squared_error(y_test_group, y_pred_group)\n",
    "        group_models[group] = {'model': stack_reg, 'mse': mse}\n",
    "\n",
    "    for group, info in sorted(group_models.items()):\n",
    "        print(f\"Group {group}: MSE = {info['mse']}\")\n",
    "    overall_mse = mean_squared_error(test_data['SalePrice'], all_predictions)\n",
    "    print(\"Overall MSE for the test dataset:\", overall_mse)\n",
    "\n",
    "    return test_data['SalePrice']\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "predicted_price = test_data_prediction(train_data, test_data)\n",
    "predicted_price"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
